{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flights Analysis (January 2008)\n",
    "\n",
    "Flights analysis is going to be performed as follows:\n",
    "\n",
    "1. PySpark **environment setup**\n",
    "2. Data source and **Spark data abstraction** (DataFrame) **set up**\n",
    "3. Data set **metadata analysis**:\n",
    "  1. Display **schema and size** of the DataFrame\n",
    "  2. Get one or multiple **random samples** from the data set to better understand what the data is all about\n",
    "  3. Identify **data entities**, **metrics** and **dimensions**\n",
    "  4. **Columns/fields categorization**\n",
    "4. Columns groups **basic profiling** to better understand our data set:\n",
    "  1. **Timing related** columns basic profiling\n",
    "  2. **Flight related** columns basic profiling\n",
    "  3. **Issue related** columns basic profiling\n",
    "5. **Answer some business questions** to improve service\n",
    "  1. **Ratio of delayed** (and no cancelled) flights by severity\n",
    "  2. **Severe delayed flights statistics** by type of delay (carrier, weather, NAS, security and lateaircraft)\n",
    "  3. **Top 20 origin airports** (and figures) involved in severe delays\n",
    "\n",
    "Let's go for it:\n",
    "\n",
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsDF = spark.read \\\n",
    "                 .option(\"inferSchema\", \"true\") \\\n",
    "                 .option(\"header\", \"true\") \\\n",
    "                 .csv(\"Data/immo_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data set metadata analysis\n",
    "### A. Display schema and size of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n",
      " |-- regio1: string (nullable = true)\n",
      " |-- serviceCharge: string (nullable = true)\n",
      " |-- heatingType: string (nullable = true)\n",
      " |-- telekomTvOffer: string (nullable = true)\n",
      " |-- telekomHybridUploadSpeed: string (nullable = true)\n",
      " |-- newlyConst: string (nullable = true)\n",
      " |-- balcony: string (nullable = true)\n",
      " |-- picturecount: string (nullable = true)\n",
      " |-- pricetrend: string (nullable = true)\n",
      " |-- telekomUploadSpeed: string (nullable = true)\n",
      " |-- totalRent: string (nullable = true)\n",
      " |-- yearConstructed: string (nullable = true)\n",
      " |-- scoutId: string (nullable = true)\n",
      " |-- noParkSpaces: string (nullable = true)\n",
      " |-- firingTypes: string (nullable = true)\n",
      " |-- hasKitchen: string (nullable = true)\n",
      " |-- geo_bln: string (nullable = true)\n",
      " |-- cellar: string (nullable = true)\n",
      " |-- yearConstructedRange: string (nullable = true)\n",
      " |-- baseRent: string (nullable = true)\n",
      " |-- houseNumber: string (nullable = true)\n",
      " |-- livingSpace: string (nullable = true)\n",
      " |-- geo_krs: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- interiorQual: string (nullable = true)\n",
      " |-- petsAllowed: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- streetPlain: string (nullable = true)\n",
      " |-- lift: string (nullable = true)\n",
      " |-- baseRentRange: string (nullable = true)\n",
      " |-- typeOfFlat: string (nullable = true)\n",
      " |-- geo_plz: string (nullable = true)\n",
      " |-- noRooms: string (nullable = true)\n",
      " |-- thermalChar: string (nullable = true)\n",
      " |-- floor: string (nullable = true)\n",
      " |-- numberOfFloors: string (nullable = true)\n",
      " |-- noRoomsRange: string (nullable = true)\n",
      " |-- garden: string (nullable = true)\n",
      " |-- livingSpaceRange: string (nullable = true)\n",
      " |-- regio2: string (nullable = true)\n",
      " |-- regio3: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- facilities: string (nullable = true)\n",
      " |-- heatingCosts: string (nullable = true)\n",
      " |-- energyEfficiencyClass: string (nullable = true)\n",
      " |-- lastRefurbish: string (nullable = true)\n",
      " |-- electricityBasePrice: string (nullable = true)\n",
      " |-- electricityKwhPrice: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n",
      "1877955\n"
     ]
    }
   ],
   "source": [
    "flightsDF.printSchema()\n",
    "print(flightsDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Get one or multiple random samples from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(Year=2008, Month=1, DayofMonth=3, DayOfWeek=4, DepTime='1039', CRSDepTime=1040, ArrTime='1132', CRSArrTime=1150, UniqueCarrier='WN', FlightNum=535, TailNum='N428WN', ActualElapsedTime='233', CRSElapsedTime=250, AirTime='219', ArrDelay='-18', DepDelay='-1', Origin='IND', Dest='LAS', Distance=1591, TaxiIn='7', TaxiOut='7', Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay='NA', WeatherDelay='NA', NASDelay='NA', SecurityDelay='NA', LateAircraftDelay='NA'),\n",
       " Row(Year=2008, Month=1, DayofMonth=3, DayOfWeek=4, DepTime='706', CRSDepTime=700, ArrTime='916', CRSArrTime=915, UniqueCarrier='WN', FlightNum=100, TailNum='N690SW', ActualElapsedTime='130', CRSElapsedTime=135, AirTime='106', ArrDelay='1', DepDelay='6', Origin='IND', Dest='MCO', Distance=828, TaxiIn='5', TaxiOut='19', Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay='NA', WeatherDelay='NA', NASDelay='NA', SecurityDelay='NA', LateAircraftDelay='NA')]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "flightsDF.cache() # optimization to make the processing faster\n",
    "flightsDF.sample(False, 0.1).take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data entities, metrics and dimensions\n",
    "\n",
    "I've identified the following elements:\n",
    "\n",
    "* **Entities:** Flight (main one which is measured - facts), Airport (dimension), Air Carrier (dimension)\n",
    "* **Metrics:** Departure time, scheduled departure time, arrival time, scheduled arrival time, ...\n",
    "* **Dimensions:** Origin, destination, tailNum, flight number, ...\n",
    "\n",
    "### D. Column categorization\n",
    "\n",
    "The following could be a potential column categorization:\n",
    "\n",
    "* **Timing related columns:** *Year*, *Month*, *DayofMonth*, *DayOfWeek*, *DepTime*, *CRSDepTime*, *ArrTime* and *CRSArrTime*\n",
    "* **Flight related columns:** *UniqueCarrier*, *FlightNum*, *TailNum*, *ActualElapsedTime*, *CRSElapsedTime*, *AirTime*, *Origin*, *Dest*, *Distance*, *TaxiIn* and *TaxiOut*\n",
    "* **Issue related columns:** *ArrDelay*, *DepDelay*, *Cancelled*, *CancellationCode*, *Diverted*, *CarrierDelay*, *WeatherDelay*, *NASDelay*, *SecurityDelay* and *LateAircraftDelay*\n",
    "\n",
    "## 4. Columns groups basic profiling to better understand our data set\n",
    "### A. Timing related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of columns Year, Month, DayofMonth and DayOfWeek:\n",
      "+-------+------+------+-----------------+------------------+\n",
      "|summary|  Year| Month|       DayofMonth|         DayOfWeek|\n",
      "+-------+------+------+-----------------+------------------+\n",
      "|  count|100000|100000|           100000|            100000|\n",
      "|   mean|2008.0|   1.0|         17.08786|           3.89004|\n",
      "| stddev|   0.0|   0.0|8.356363976550366|1.9529994727263522|\n",
      "|    min|  2008|     1|                1|                 1|\n",
      "|    25%|  2008|     1|               10|                 2|\n",
      "|    50%|  2008|     1|               17|                 4|\n",
      "|    75%|  2008|     1|               24|                 5|\n",
      "|    max|  2008|     1|               31|                 7|\n",
      "+-------+------+------+-----------------+------------------+\n",
      "\n",
      "Checking for nulls on columns Year, Month, DayofMonth and DayOfWeek:\n",
      "+----+-----+----------+---------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|\n",
      "+----+-----+----------+---------+\n",
      "|   0|    0|         0|        0|\n",
      "+----+-----+----------+---------+\n",
      "\n",
      "Checking amount of distinct values in columns Year, Month, DayofMonth and DayOfWeek:\n",
      "+----+-----+----------+---------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|\n",
      "+----+-----+----------+---------+\n",
      "|   1|    1|        31|        7|\n",
      "+----+-----+----------+---------+\n",
      "\n",
      "Most and least frequent occurrences for DayofMonth and DayOfWeek columns:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n| leastFreqDayOfMonth | mostFreqDayOfMonth | leastFreqDayOfWeek | mostFreqDayOfWeek |\n|----|----|----|----|\n| 2 (188 occurrences) | 11 (3639 occurrences) | 6 (11285 occurrences) | 4 (17079 occurrences) |\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|          DepTime|        CRSDepTime|           ArrTime|        CRSArrTime|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|           100000|            100000|            100000|            100000|\n",
      "|   mean|1355.200722248073|         1341.9894|1492.7392247056678|        1502.60154|\n",
      "| stddev|464.0896318178077|451.35698421417186| 496.3767939169903|478.10021559061414|\n",
      "|    min|                1|               600|                 1|                 5|\n",
      "|    25%|            942.0|               940|            1114.0|              1120|\n",
      "|    50%|           1344.0|              1335|            1518.0|              1520|\n",
      "|    75%|           1743.0|              1730|            1913.0|              1910|\n",
      "|    max|               NA|              2235|                NA|              2355|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n",
      "Checking for nulls on columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\n",
      "+-------+----------+-------+----------+\n",
      "|DepTime|CRSDepTime|ArrTime|CRSArrTime|\n",
      "+-------+----------+-------+----------+\n",
      "|      0|         0|      0|         0|\n",
      "+-------+----------+-------+----------+\n",
      "\n",
      "Checking amount of distinct values in columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\n",
      "+-------+----------+-------+----------+\n",
      "|DepTime|CRSDepTime|ArrTime|CRSArrTime|\n",
      "+-------+----------+-------+----------+\n",
      "|   1155|       213|   1294|       402|\n",
      "+-------+----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first, lit\n",
    "\n",
    "\n",
    "print (\"Summary of columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select(\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns Year, Month, DayofMonth and DayOfWeek:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\"]]).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"Most and least frequent occurrences for DayofMonth and DayOfWeek columns:\")\n",
    "dayofMonthOccurrencesDF = flightsDF.groupBy(\"DayofMonth\").agg(count(lit(1)).alias(\"Total\"))\n",
    "dayOfWeekDF = flightsDF.groupBy(\"DayOfWeek\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "leastFreqDayOfMonth    = dayofMonthOccurrencesDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDayOfMonth     = dayofMonthOccurrencesDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqDayOfWeek     = dayOfWeekDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDayOfWeek      = dayOfWeekDF.orderBy(col(\"Total\").desc()).first()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqDayOfMonth\", \"mostFreqDayOfMonth\", \"leastFreqDayOfWeek\", \"mostFreqDayOfWeek\", \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqDayOfMonth[\"DayofMonth\"], leastFreqDayOfMonth[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqDayOfMonth[\"DayofMonth\"], mostFreqDayOfMonth[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqDayOfWeek[\"DayOfWeek\"], leastFreqDayOfWeek[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqDayOfWeek[\"DayOfWeek\"], mostFreqDayOfWeek[\"Total\"]))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print (\"Summary of columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select(\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns DepTime, CRSDepTime, ArrTime and CRSArrTime:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\"]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Flight related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\n",
      "+-------+-------------+------------------+-------+------+------+-----------------+\n",
      "|summary|UniqueCarrier|         FlightNum|TailNum|Origin|  Dest|         Distance|\n",
      "+-------+-------------+------------------+-------+------+------+-----------------+\n",
      "|  count|       100000|            100000|  98858|100000|100000|           100000|\n",
      "|   mean|         null|        1510.64854|   null|  null|  null|        630.58632|\n",
      "| stddev|         null|1186.1285980391729|   null|  null|  null|437.3570752611293|\n",
      "|    min|           WN|                 1| N11109|   ABQ|   ABQ|               66|\n",
      "|    25%|         null|               502|   null|  null|  null|              324|\n",
      "|    50%|         null|              1320|   null|  null|  null|              453|\n",
      "|    75%|         null|              2362|   null|  null|  null|              843|\n",
      "|    max|           XE|              7676|   N906|   TUS|   XNA|             2363|\n",
      "+-------+-------------+------------------+-------+------+------+-----------------+\n",
      "\n",
      "Checking for nulls on columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "|UniqueCarrier|FlightNum|TailNum|Origin|Dest|Distance|\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "|            0|        0|   1142|     0|   0|       0|\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "\n",
      "Checking amount of distinct values in columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "|UniqueCarrier|FlightNum|TailNum|Origin|Dest|Distance|\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "|            2|     2669|    623|    82|  81|     445|\n",
      "+-------------+---------+-------+------+----+--------+\n",
      "\n",
      "Most and least frequent occurrences for FlightNum, TailNum, Origin and Dest columns:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n| leastFreqFlightNum | mostFreqFlightNum | leastFreqTailNum | mostFreqTailNum |\n|----|----|----|----|\n| 2711 (1 occurrences) | 224 (256 occurrences) | N13118 (1 occurrences) | None (1142 occurrences) |\n"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "\n| leastFreqOrigin | mostFreqOrigin | leastFreqDest | mostFreqDest |\n|----|----|----|----|\n| CRW (1 occurrences) | LAS (6817 occurrences) | MYR (1 occurrences) | LAS (6734 occurrences) |\n"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\n",
      "+-------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "|summary| ActualElapsedTime|   CRSElapsedTime|          AirTime|           TaxiIn|           TaxiOut|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "|  count|            100000|           100000|           100000|           100000|            100000|\n",
      "|   mean|107.55850169203023|        111.98954| 91.8637966321506|4.768961883726114|10.927765077181412|\n",
      "| stddev|    55.35097080091|57.20913510480459|54.20822434609592|2.983635448088949| 5.989579591427709|\n",
      "|    min|               100|               17|              100|                1|                 1|\n",
      "|    25%|              68.0|               70|             53.0|              3.0|               8.0|\n",
      "|    50%|              88.0|               90|             71.0|              4.0|               9.0|\n",
      "|    75%|             135.0|              145|            118.0|              5.0|              12.0|\n",
      "|    max|                NA|              370|               NA|               NA|                NA|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+------------------+\n",
      "\n",
      "Checking for nulls on columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "|ActualElapsedTime|CRSElapsedTime|AirTime|TaxiIn|TaxiOut|\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "|                0|             0|      0|     0|      0|\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "\n",
      "Checking amount of distinct values in columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "|ActualElapsedTime|CRSElapsedTime|AirTime|TaxiIn|TaxiOut|\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "|              344|           157|    339|    58|    114|\n",
      "+-----------------+--------------+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first\n",
    "\n",
    "print (\"Summary of columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select(\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns UniqueCarrier, FlightNum, TailNum, Origin, Dest and Distance:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"UniqueCarrier\", \"FlightNum\", \"TailNum\", \"Origin\", \"Dest\", \"Distance\"]]).show()\n",
    "\n",
    "print (\"Most and least frequent occurrences for FlightNum, TailNum, Origin and Dest columns:\")\n",
    "FlightNumDF = flightsDF.groupBy(\"FlightNum\").agg(count(lit(1)).alias(\"Total\"))\n",
    "TailNumDF   = flightsDF.groupBy(\"TailNum\").agg(count(lit(1)).alias(\"Total\"))\n",
    "OriginDF    = flightsDF.groupBy(\"Origin\").agg(count(lit(1)).alias(\"Total\"))\n",
    "DestDF      = flightsDF.groupBy(\"Dest\").agg(count(lit(1)).alias(\"Total\"))\n",
    "\n",
    "leastFreqFlightNum    = FlightNumDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqFlightNum     = FlightNumDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqTailNum      = TailNumDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqTailNum       = TailNumDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqOrigin       = OriginDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqOrigin        = OriginDF.orderBy(col(\"Total\").desc()).first()\n",
    "leastFreqDest         = DestDF.orderBy(col(\"Total\").asc()).first()\n",
    "mostFreqDest          = DestDF.orderBy(col(\"Total\").desc()).first()\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqFlightNum\", \"mostFreqFlightNum\", \"leastFreqTailNum\", \"mostFreqTailNum\", \\\n",
    "       \"%d (%d occurrences)\" % (leastFreqFlightNum[\"FlightNum\"], leastFreqFlightNum[\"Total\"]), \\\n",
    "       \"%d (%d occurrences)\" % (mostFreqFlightNum[\"FlightNum\"], mostFreqFlightNum[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqTailNum[\"TailNum\"], leastFreqTailNum[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqTailNum[\"TailNum\"], mostFreqTailNum[\"Total\"]))))\n",
    "display(Markdown(\"\"\"\n",
    "| %s | %s | %s | %s |\n",
    "|----|----|----|----|\n",
    "| %s | %s | %s | %s |\n",
    "\"\"\" % (\"leastFreqOrigin\", \"mostFreqOrigin\", \"leastFreqDest\", \"mostFreqDest\", \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqOrigin[\"Origin\"], leastFreqOrigin[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqOrigin[\"Origin\"], mostFreqOrigin[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (leastFreqDest[\"Dest\"], leastFreqDest[\"Total\"]), \\\n",
    "       \"%s (%d occurrences)\" % (mostFreqDest[\"Dest\"], mostFreqDest[\"Total\"]))))\n",
    "\n",
    "print (\"Summary of columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select(\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns ActualElapsedTime, CRSElapsedTime, AirTime, TaxiIn and TaxiOut:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"ActualElapsedTime\", \"CRSElapsedTime\", \"AirTime\", \"TaxiIn\", \"TaxiOut\"]]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Issue related columns basic profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Summary of columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\n",
      "+-------+-----------------+------------------+-------------------+----------------+------------------+\n",
      "|summary|         ArrDelay|          DepDelay|          Cancelled|CancellationCode|          Diverted|\n",
      "+-------+-----------------+------------------+-------------------+----------------+------------------+\n",
      "|  count|           100000|            100000|             100000|            1142|            100000|\n",
      "|   mean|5.729954001094247|10.379048736571649|            0.01142|            null|            0.0016|\n",
      "| stddev|30.96695927246462|28.384428068170866|0.10625298347324127|            null|0.0399681870311844|\n",
      "|    min|               -1|                -1|                  0|               A|                 0|\n",
      "|    25%|             -9.0|              -2.0|                  0|            null|                 0|\n",
      "|    50%|             -2.0|               1.0|                  0|            null|                 0|\n",
      "|    75%|             10.0|              10.0|                  0|            null|                 0|\n",
      "|    max|               NA|                NA|                  1|               C|                 1|\n",
      "+-------+-----------------+------------------+-------------------+----------------+------------------+\n",
      "\n",
      "Checking for nulls on columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\n",
      "+--------+--------+---------+----------------+--------+\n",
      "|ArrDelay|DepDelay|Cancelled|CancellationCode|Diverted|\n",
      "+--------+--------+---------+----------------+--------+\n",
      "|       0|       0|        0|           98858|       0|\n",
      "+--------+--------+---------+----------------+--------+\n",
      "\n",
      "Checking amount of distinct values in columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\n",
      "+--------+--------+---------+----------------+--------+\n",
      "|ArrDelay|DepDelay|Cancelled|CancellationCode|Diverted|\n",
      "+--------+--------+---------+----------------+--------+\n",
      "|     391|     354|        2|               3|       2|\n",
      "+--------+--------+---------+----------------+--------+\n",
      "\n",
      "Summary of columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\n",
      "+-------+-----------------+------------------+-----------------+-------------------+-----------------+\n",
      "|summary|     CarrierDelay|      WeatherDelay|         NASDelay|      SecurityDelay|LateAircraftDelay|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+-----------------+\n",
      "|  count|           100000|            100000|           100000|             100000|           100000|\n",
      "|   mean|9.573488206225482|2.0361200264914157|8.353150950124816|0.11080544092923736|29.34367517448673|\n",
      "| stddev|21.83683640672927|13.815867838905518|18.82608664849725| 1.7248882167846213|39.75352889072861|\n",
      "|    min|                0|                 0|                0|                  0|                0|\n",
      "|    25%|              0.0|               0.0|              0.0|                0.0|              1.0|\n",
      "|    50%|              1.0|               0.0|              0.0|                0.0|             18.0|\n",
      "|    75%|            431.0|               0.0|            366.0|                0.0|            434.0|\n",
      "|    max|               NA|                NA|               NA|                 NA|               NA|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+-----------------+\n",
      "\n",
      "Checking for nulls on columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "|           0|           0|       0|            0|                0|\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "\n",
      "Checking amount of distinct values in columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "|         210|         170|     192|           39|              288|\n",
      "+------------+------------+--------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pyspark.sql.functions import when, count, col, countDistinct, desc, first\n",
    "\n",
    "print (\"Summary of columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select(\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns ArrDelay, DepDelay, Cancelled, CancellationCode and Diverted:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"ArrDelay\", \"DepDelay\", \"Cancelled\", \"CancellationCode\", \"Diverted\"]]).show()\n",
    "\n",
    "print (\"Summary of columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select(\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\").summary().show()\n",
    "\n",
    "print(\"Checking for nulls on columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select([count(when(col(c).isNull(), c)).alias(c) for c in [\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]]).show()\n",
    "\n",
    "print(\"Checking amount of distinct values in columns CarrierDelay, WeatherDelay, NASDelay, SecurityDelay and LateAircraftDelay:\")\n",
    "flightsDF.select([countDistinct(c).alias(c) for c in [\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Answer some business questions to improve service\n",
    "\n",
    "### A. Ratio of delayed (and no cancelled) flights by severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+----------+------------+\n| DelaySeverity|NumFlights|RoundedRatio|\n+--------------+----------+------------+\n|     1.nodelay|     57143|       57.14|\n|  2.acceptable|     22761|       22.76|\n|    3.annoying|      8101|         8.1|\n|    4.impactul|      6050|        6.05|\n|5.unacceptable|      4643|        4.64|\n+--------------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, round\n",
    "\n",
    "# Delay severity is going to be categorized as follows (totally made up):\n",
    "#\n",
    "#   \"nodelay\"      - delay=(-infinity,0] mins\n",
    "#   \"acceptable\"   - delay=(0,15] mins\n",
    "#   \"annoying\"     - delay=(15,30] mins\n",
    "#   \"impactul\"     - delay=(30,60] mins\n",
    "#   \"unacceptable\" - delay=(60,+infinity) mins\n",
    "\n",
    "# 1. Let's enrich the DF with delay severity based on our categorization\n",
    "totalFlights = flightsDF.count()\n",
    "delayCategorizationDF = flightsDF\\\n",
    "   .where(col(\"ArrDelay\")!=\"NA\")\\\n",
    "   .withColumn(\"DelaySeverity\", when(col(\"ArrDelay\")<=0,\"1.nodelay\")\\\n",
    "                               .when((col(\"ArrDelay\")>0) & (col(\"ArrDelay\")<=15),\"2.acceptable\")\\\n",
    "                               .when((col(\"ArrDelay\")>15) & (col(\"ArrDelay\")<=30),\"3.annoying\")\\\n",
    "                               .when((col(\"ArrDelay\")>30) & (col(\"ArrDelay\")<=60),\"4.impactul\")\\\n",
    "                               .otherwise(\"5.unacceptable\"))\n",
    "delayCategorizationDF.cache() # optimization to make the processing faster\n",
    "# 2. Ready to answer to this business question\n",
    "delayCategorizationDF.where(col(\"Cancelled\")==0)\\\n",
    "                     .select(\"DelaySeverity\", \"ArrDelay\")\\\n",
    "                     .groupBy(\"DelaySeverity\")\\\n",
    "                     .agg(count(\"DelaySeverity\").alias(\"NumFlights\"), \\\n",
    "                          (count(\"DelaySeverity\")/totalFlights*100).alias(\"Ratio\"))\\\n",
    "                     .orderBy(\"DelaySeverity\")\\\n",
    "                     .select(\"DelaySeverity\",\"NumFlights\",round(\"Ratio\",2).alias(\"RoundedRatio\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Severe delayed flights statistics by type of delay (carrier, weather, NAS, security and lateaircraft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'Arrival' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+------------------+-----------+------------+------------------+\n| DelaySeverity|      AverageDelay|LowestDelay|HighestDelay|       StdDevDelay|\n+--------------+------------------+-----------+------------+------------------+\n|    3.annoying| 21.97555857301568|         16|          30| 4.204130253081042|\n|    4.impactul| 42.49900826446281|         31|          60| 8.490116530348118|\n|5.unacceptable|112.50118457893603|         61|         500|55.535970510739816|\n+--------------+------------------+-----------+------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'Carrier' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+-----------------+-----------+------------+-----------------+\n| DelaySeverity|     AverageDelay|LowestDelay|HighestDelay|      StdDevDelay|\n+--------------+-----------------+-----------+------------+-----------------+\n|    3.annoying|5.307616343661277|          0|          30|7.465239778273078|\n|    4.impactul| 9.72809917355372|          0|          60|14.06377159723449|\n|5.unacceptable|17.89511091966401|          0|         431|39.35785159709625|\n+--------------+-----------------+-----------+------------+-----------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'Weather' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+-------------------+-----------+------------+------------------+\n| DelaySeverity|       AverageDelay|LowestDelay|HighestDelay|       StdDevDelay|\n+--------------+-------------------+-----------+------------+------------------+\n|    3.annoying|0.25367238612516974|          0|          28| 1.996159994036475|\n|    4.impactul| 0.8046280991735537|          0|          60| 4.891432829821254|\n|5.unacceptable|  7.095843204824467|          0|         267|27.110169659379295|\n+--------------+-------------------+-----------+------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'NAS' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+------------------+-----------+------------+------------------+\n| DelaySeverity|      AverageDelay|LowestDelay|HighestDelay|       StdDevDelay|\n+--------------+------------------+-----------+------------+------------------+\n|    3.annoying|5.6590544377237375|          0|          30| 7.991772840270974|\n|    4.impactul|  6.91702479338843|          0|          60|11.897814956328913|\n|5.unacceptable|15.459616627180703|          0|         366|33.584072958913225|\n+--------------+------------------+-----------+------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'Security' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+-------------------+-----------+------------+------------------+\n| DelaySeverity|       AverageDelay|LowestDelay|HighestDelay|       StdDevDelay|\n+--------------+-------------------+-----------+------------+------------------+\n|    3.annoying|0.11122083693371189|          0|          28|1.2349234007295635|\n|    4.impactul|0.11123966942148761|          0|          48|1.6527896485929991|\n|5.unacceptable|0.10618134826620719|          0|          88|  2.47445599778738|\n+--------------+-------------------+-----------+------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**'LateAircraft' severe delays basic stats** (in mins):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+------------------+-----------+------------+------------------+\n| DelaySeverity|      AverageDelay|LowestDelay|HighestDelay|       StdDevDelay|\n+--------------+------------------+-----------+------------+------------------+\n|    3.annoying|10.643994568571781|          0|          30| 9.288445499357707|\n|    4.impactul| 24.93801652892562|          0|          60|17.331641832099727|\n|5.unacceptable| 71.94443247900064|          0|         434| 59.86123488142751|\n+--------------+------------------+-----------+------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, min, avg, stddev\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# To get statistics of severe delayed flights, we have to prepare the previous DataFrame (delayCategorizationDF):\n",
    "#   1. Remove cancelled flights\n",
    "#   2. Keep only severe delayed flights: annoying, impactful and unacceptable\n",
    "#   3. To get proper statistics, convert String columns with delay info into Integer columns\n",
    "#      (none of the converted fields contain \"NA\" as value in severeDelaysDF - you can easily check this out) \n",
    "#\n",
    "severeDelaysDF = \\\n",
    "  delayCategorizationDF.where((col(\"Cancelled\")==0))\\\n",
    "                       .where((col(\"DelaySeverity\")!=\"1.nodelay\") & (col(\"DelaySeverity\")!=\"2.acceptable\"))\\\n",
    "                       .withColumn(\"IntArrDelay\", col(\"ArrDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntCarrierDelay\", col(\"CarrierDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntWeatherDelay\", col(\"WeatherDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntNASDelay\", col(\"NASDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntSecurityDelay\", col(\"SecurityDelay\").cast(IntegerType()))\\\n",
    "                       .withColumn(\"IntLateAircraftDelay\", col(\"LateAircraftDelay\").cast(IntegerType()))\\\n",
    "                       .select(\"DelaySeverity\", \"IntArrDelay\",\"IntCarrierDelay\",\"IntWeatherDelay\",\\\n",
    "                               \"IntNASDelay\", \"IntSecurityDelay\", \"IntLateAircraftDelay\")\n",
    "severeDelaysDF.cache() # optimization to make the processing faster\n",
    "\n",
    "display(Markdown(\"**'Arrival' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntArrDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntArrDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntArrDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntArrDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Carrier' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntCarrierDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntCarrierDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntCarrierDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntCarrierDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Weather' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntWeatherDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntWeatherDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntWeatherDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntWeatherDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'NAS' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntNASDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntNASDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntNASDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntNASDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'Security' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntSecurityDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntSecurityDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntSecurityDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntSecurityDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()\n",
    "\n",
    "display(Markdown(\"**'LateAircraft' severe delays basic stats** (in mins):\"))\n",
    "severeDelaysDF.groupBy(\"DelaySeverity\")\\\n",
    "              .agg(avg(\"IntLateAircraftDelay\").alias(\"AverageDelay\"),\\\n",
    "                   min(\"IntLateAircraftDelay\").alias(\"LowestDelay\"),\\\n",
    "                   max(\"IntLateAircraftDelay\").alias(\"HighestDelay\"),\\\n",
    "                   stddev(\"IntLateAircraftDelay\").alias(\"StdDevDelay\"))\\\n",
    "              .orderBy(\"DelaySeverity\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Top 20 origin airports (and figures) involved in severe delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**Top 20 origin airports** with highest severe delayed (**unacceptable**) flights ratio (in \\%):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+--------------+-----------------------+------------+------------------+\n|Origin| DelaySeverity|NumSevereDelayedFlights|TotalFlights|SevereDelayedRatio|\n+------+--------------+-----------------------+------------+------------------+\n|   LCH|    4.impactul|                      1|           1|             100.0|\n|   ORD|    4.impactul|                      1|           1|             100.0|\n|   SYR|    4.impactul|                      1|           1|             100.0|\n|   IAH|    4.impactul|                      2|           9|             22.22|\n|   SFO|5.unacceptable|                    154|         743|             20.73|\n|   COS|    3.annoying|                     23|         181|             12.71|\n|   LAS|    3.annoying|                    743|        6817|              10.9|\n|   GEG|    3.annoying|                     73|         673|             10.85|\n|   MAF|    3.annoying|                     34|         329|             10.33|\n|   BOI|    3.annoying|                     64|         627|             10.21|\n|   LAX|    3.annoying|                    332|        3369|              9.85|\n|   SLC|    3.annoying|                    151|        1534|              9.84|\n|   ONT|    3.annoying|                    222|        2275|              9.76|\n|   BUR|    3.annoying|                    156|        1613|              9.67|\n|   RNO|    3.annoying|                    122|        1272|              9.59|\n|   OMA|    3.annoying|                     55|         575|              9.57|\n|   SLC|5.unacceptable|                    146|        1534|              9.52|\n|   OAK|    3.annoying|                    368|        3949|              9.32|\n|   STL|    3.annoying|                    188|        2036|              9.23|\n|   LAX|    4.impactul|                    310|        3369|               9.2|\n+------+--------------+-----------------------+------------+------------------+\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "**Top 20 origin airports with severe delayed flights ratio** by severity category (in \\%):"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+----------+----------+--------------+\n|Origin|3.annoying|4.impactul|5.unacceptable|\n+------+----------+----------+--------------+\n|   SFO|      7.67|      6.46|         20.73|\n|   SLC|      9.84|      7.89|          9.52|\n|   BFL|      3.28|      4.92|           8.2|\n|   LAX|      9.85|       9.2|          7.48|\n|   LAS|      10.9|      8.32|          7.16|\n|   EWR|      7.14|      7.14|          7.14|\n|   SAN|      8.67|      8.46|          7.12|\n|   MDW|      8.88|      7.42|          6.78|\n|   GEG|     10.85|       5.5|          6.09|\n|   OAK|      9.32|      7.72|           6.0|\n|   RNO|      9.59|      7.31|           5.9|\n|   BOI|     10.21|      6.86|          5.58|\n|   COS|     12.71|      6.08|          5.52|\n|   FAT|      2.07|      4.14|          5.52|\n|   SJC|      8.06|      7.78|          5.33|\n|   LGB|      7.41|      2.96|          5.19|\n|   SMF|      8.62|      6.89|          4.97|\n|   PDX|      6.86|      6.69|          4.85|\n|   TUS|      7.49|      6.49|          4.81|\n|   BUR|      9.67|      7.69|          4.71|\n+------+----------+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Our answer to this business question will be:\n",
    "#   1. List of top 20 origin airports with highest severe delayed (aka unacceptable) flights ratio \n",
    "#      (based on total number of flights)\n",
    "#   2. List of top 20 origin airports with severe delayed flights ratio by severity category (unacceptable,\n",
    "#      impactful and annoying)\n",
    "\n",
    "# In order to be able to deliver these insights, we need some preparation:\n",
    "#   1. Define a DataFrame with total flights per Origin airport (totalFlightsOriginDF)\n",
    "#   2. Define a DataFrame with aggregated data by Origin and DelaySeverity to figure out\n",
    "#      number of flights delayed per severity category (severeDelaysOriginDF)\n",
    "#   3. Combine both DataFrames to come up with one single DataFrame containin total flights\n",
    "#      per origin airport and number of flights delayed by severity to compute ratios (combinedDF)\n",
    "\n",
    "totalFlightsOriginDF = \\\n",
    "   flightsDF.groupBy(\"Origin\")\\\n",
    "            .agg(count(lit(1)).alias(\"TotalFlights\"))\n",
    "severeDelaysOriginDF = \\\n",
    "  delayCategorizationDF.where((col(\"Cancelled\")==0))\\\n",
    "                       .where((col(\"DelaySeverity\")!=\"1.nodelay\") & (col(\"DelaySeverity\")!=\"2.acceptable\"))\\\n",
    "                       .select(\"Origin\", \"DelaySeverity\")\\\n",
    "                       .groupBy(\"Origin\", \"DelaySeverity\")\\\n",
    "                       .agg(count(lit(1)).alias(\"NumSevereDelayedFlights\"))\n",
    "\n",
    "combinedDF = \\\n",
    "  severeDelaysOriginDF\\\n",
    "     .join(totalFlightsOriginDF, \"Origin\")\\\n",
    "     .withColumn(\"SevereDelayedRatio\", round(col(\"NumSevereDelayedFlights\")/col(\"TotalFlights\")*100,2))\\\n",
    "     .orderBy(col(\"SevereDelayedRatio\").desc())\n",
    "combinedDF.cache() # optimization to make the processing faster\n",
    "\n",
    "display(Markdown(\"**Top 20 origin airports** with highest severe delayed (**unacceptable**) flights ratio (in \\%):\"))\n",
    "combinedDF.limit(20).show()\n",
    "display(Markdown(\"**Top 20 origin airports with severe delayed flights ratio** by severity category (in \\%):\"))\n",
    "combinedDF\\\n",
    "   .groupBy(\"Origin\")\\\n",
    "   .pivot(\"DelaySeverity\")\\\n",
    "   .min(\"SevereDelayedRatio\")\\\n",
    "   .orderBy(col(\"`5.unacceptable`\").desc(), col(\"`4.impactul`\").desc(), col(\"`3.annoying`\").desc())\\\n",
    "   .limit(20).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}