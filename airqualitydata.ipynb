{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Madrid's Air Quality Analysis (2018-2019)\n",
    "\n",
    "Throughout the following Jupyter Notebook you're going to analyze the **air quality in Madrid** from **January 2018** to **November 2019**, by using the **Spark skills** you've learned during the **Spark Course**.\n",
    "\n",
    "Data set used is coming from the [Madrid Town's Open Data Portal](https://datos.madrid.es/), specifically, from the [Real-time Air Quality](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=41e01e007c9db410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default) section. **Documentation on the data set is available** in this [link](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf), although *it's in Spanish*. The document will be used as a reference and *translated as needed*.\n",
    "\n",
    "## 1. PySpark environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data source and Spark data abstraction (DataFrame) setup\n",
    "To-do:\n",
    "- Download file `airqualitydata_madrid1819.zip` file from \"Additional Documentation\" to your laptop.\n",
    "- Unzip the downloaded file. This creates a folder called `airqualitydata` in your laptop containing *23 CSV files* (Dec'19 is not in there).\n",
    "- Create a folder (ex. `airqualitydata`) in Jupyter.\n",
    "- Go into that folder and upload the 23 files.\n",
    "- Create a **custom schema** manually to translate CSV files headers:\n",
    "  - PROVINCE => `IntegerType`\n",
    "  - TOWN => `IntegerType`\n",
    "  - STATION => `IntegerType`\n",
    "  - MAGNITUDE => `IntegerType`\n",
    "  - SAMPLING_LOCATION => `StringType`\n",
    "  - YEAR => `IntegerType`\n",
    "  - MONTH => `IntegerType`\n",
    "  - DAY => `IntegerType`\n",
    "  - H01 => `DoubleType`\n",
    "  - V01 => `StringType`\n",
    "  - H02 => `DoubleType`\n",
    "  - V02 => `StringType`\n",
    "  - H03 => `DoubleType`\n",
    "  - V03 => `StringType`\n",
    "  - H04 => `DoubleType`\n",
    "  - V04 => `StringType`\n",
    "  - H05 => `DoubleType`\n",
    "  - V05 => `StringType`\n",
    "  - H06 => `DoubleType`\n",
    "  - V06 => `StringType`\n",
    "  - H07 => `DoubleType`\n",
    "  - V07 => `StringType`\n",
    "  - H08 => `DoubleType`\n",
    "  - V08 => `StringType`\n",
    "  - H09 => `DoubleType`\n",
    "  - V09 => `StringType`\n",
    "  - H10 => `DoubleType`\n",
    "  - V10 => `StringType`\n",
    "  - H11 => `DoubleType`\n",
    "  - V11 => `StringType`\n",
    "  - H12 => `DoubleType`\n",
    "  - V12 => `StringType`\n",
    "  - H13 => `DoubleType`\n",
    "  - V13 => `StringType`\n",
    "  - H14 => `DoubleType`\n",
    "  - V14 => `StringType`\n",
    "  - H15 => `DoubleType`\n",
    "  - V15 => `StringType`\n",
    "  - H16 => `DoubleType`\n",
    "  - V16 => `StringType`\n",
    "  - H17 => `DoubleType`\n",
    "  - V17 => `StringType`\n",
    "  - H18 => `DoubleType`\n",
    "  - V18 => `StringType`\n",
    "  - H19 => `DoubleType`\n",
    "  - V19 => `StringType`\n",
    "  - H20 => `DoubleType`\n",
    "  - V20 => `StringType`\n",
    "  - H21 => `DoubleType`\n",
    "  - V21 => `StringType`\n",
    "  - H22 => `DoubleType`\n",
    "  - V22 => `StringType`\n",
    "  - H23 => `DoubleType`\n",
    "  - V23 => `StringType`\n",
    "  - H24 => `DoubleType`\n",
    "  - V24 => `StringType`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "\n",
    "aqSchema = StructType(\\\n",
    "    [StructField(\"PROVINCE\",IntegerType(),True),\\\n",
    "     StructField(\"TOWN\",IntegerType(),True),\\\n",
    "     StructField(\"STATION\",IntegerType(),True),\\\n",
    "     StructField(\"MAGNITUDE\",IntegerType(),True),\\\n",
    "     StructField(\"SAMPLING_LOCATION\",StringType(),True),\\\n",
    "     StructField(\"YEAR\",IntegerType(),True),\\\n",
    "     StructField(\"MONTH\",IntegerType(),True),\\\n",
    "     StructField(\"DAY\",IntegerType(),True),\\\n",
    "     StructField(\"H01\",DoubleType(),True),\\\n",
    "     StructField(\"V01\",StringType(),True),\\\n",
    "     StructField(\"H02\",DoubleType(),True),\\\n",
    "     StructField(\"V02\",StringType(),True),\\\n",
    "     StructField(\"H03\",DoubleType(),True),\\\n",
    "     StructField(\"V03\",StringType(),True),\\\n",
    "     StructField(\"H04\",DoubleType(),True),\\\n",
    "     StructField(\"V04\",StringType(),True),\\\n",
    "     StructField(\"H05\",DoubleType(),True),\\\n",
    "     StructField(\"V05\",StringType(),True),\\\n",
    "     StructField(\"H06\",DoubleType(),True),\\\n",
    "     StructField(\"V06\",StringType(),True),\\\n",
    "     StructField(\"H07\",DoubleType(),True),\\\n",
    "     StructField(\"V07\",StringType(),True),\\\n",
    "     StructField(\"H08\",DoubleType(),True),\\\n",
    "     StructField(\"V08\",StringType(),True),\\\n",
    "     StructField(\"H09\",DoubleType(),True),\\\n",
    "     StructField(\"V09\",StringType(),True),\\\n",
    "     StructField(\"H10\",DoubleType(),True),\\\n",
    "     StructField(\"V10\",StringType(),True),\\\n",
    "     StructField(\"H11\",DoubleType(),True),\\\n",
    "     StructField(\"V11\",StringType(),True),\\\n",
    "     StructField(\"H12\",DoubleType(),True),\\\n",
    "     StructField(\"V12\",StringType(),True),\\\n",
    "     StructField(\"H13\",DoubleType(),True),\\\n",
    "     StructField(\"V13\",StringType(),True),\\\n",
    "     StructField(\"H14\",DoubleType(),True),\\\n",
    "     StructField(\"V14\",StringType(),True),\\\n",
    "     StructField(\"H15\",DoubleType(),True),\\\n",
    "     StructField(\"V15\",StringType(),True),\\\n",
    "     StructField(\"H16\",DoubleType(),True),\\\n",
    "     StructField(\"V16\",StringType(),True),\\\n",
    "     StructField(\"H17\",DoubleType(),True),\\\n",
    "     StructField(\"V17\",StringType(),True),\\\n",
    "     StructField(\"H18\",DoubleType(),True),\\\n",
    "     StructField(\"V18\",StringType(),True),\\\n",
    "     StructField(\"H19\",DoubleType(),True),\\\n",
    "     StructField(\"V19\",StringType(),True),\\\n",
    "     StructField(\"H20\",DoubleType(),True),\\\n",
    "     StructField(\"V20\",StringType(),True),\\\n",
    "     StructField(\"H21\",DoubleType(),True),\\\n",
    "     StructField(\"V21\",StringType(),True),\\\n",
    "     StructField(\"H22\",DoubleType(),True),\\\n",
    "     StructField(\"V22\",StringType(),True),\\\n",
    "     StructField(\"H23\",DoubleType(),True),\\\n",
    "     StructField(\"V23\",StringType(),True),\\\n",
    "     StructField(\"H24\",DoubleType(),True),\\\n",
    "     StructField(\"V24\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the `read` method to create the DataFrame (called `aqDF`).\n",
    "- Display the first Row of the DataFrame and the number of rows in the DataFrame.\n",
    "\n",
    "\n",
    "Hints:\n",
    "- `read` method/function can handle multiple CSV files inside a folder at once (see [this](https://stackoverflow.com/questions/37639956/how-to-import-multiple-csv-files-in-a-single-load))\n",
    "- Pay attention to the columns delimiter. Fields are not always separated by commas and that has to be handled accordingly via options (see [this](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=csv#pyspark.sql.DataFrameReader.csv))\n",
    "- In the end you should get **56 fields/columns** and **105,050 rows**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(PROVINCE=28, TOWN=79, STATION=4, MAGNITUDE=1, SAMPLING_LOCATION='28079004_1_38', YEAR=2019, MONTH=10, DAY=1, H01=10.0, V01='V', H02=10.0, V02='V', H03=9.0, V03='V', H04=9.0, V04='V', H05=9.0, V05='V', H06=9.0, V06='V', H07=9.0, V07='V', H08=12.0, V08='V', H09=15.0, V09='V', H10=19.0, V10='V', H11=16.0, V11='V', H12=13.0, V12='V', H13=10.0, V13='V', H14=8.0, V14='V', H15=6.0, V15='V', H16=7.0, V16='V', H17=7.0, V17='V', H18=7.0, V18='V', H19=7.0, V19='V', H20=7.0, V20='V', H21=7.0, V21='V', H22=8.0, V22='V', H23=8.0, V23='V', H24=9.0, V24='V')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "aqDF = spark.read.schema(aqSchema).option(\"header\", \"true\").option(\"sep\", \";\").csv(\"Data/airqualitydata/*.csv\")\n",
    "aqDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "This DataFrame has **105050 rows**."
     },
     "metadata": {}
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(\"This DataFrame has **%d rows**.\" % aqDF.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a DataFrame manually (call it `magnitudesDF`) with the contents in the table **\"Magnitudes, units and measurement techniques\"**, available in **page 5/Appendix II** from the [aforementioned documentation](https://datos.madrid.es/FWProjects/egob/Catalogo/MedioAmbiente/Aire/Ficheros/Interprete_ficheros_%20calidad_%20del_%20aire_global.pdf).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------------------+-------+------+-----------+--------------------+\n|magnitudeId|       magnitudeName|formula|  unit|techniqueId|       techniqueName|\n+-----------+--------------------+-------+------+-----------+--------------------+\n|          1|     Sulphur dioxide|    SO2|ug/m^3|         38|Ultraviolet fluor...|\n|          6|     Carbon monoxide|     CO|mg/m^3|         48| Infrared absorption|\n|          7|   Nitrogen monoxide|     NO|ug/m^3|          8|   Chemiluminescence|\n|          8|    Nitrogen dioxide|    NO2|ug/m^3|          8|                 Id.|\n|          9|   Particles < 250um|  PM2.5|ug/m^3|         47|        Microbalance|\n|         10|    Particles < 10um|   PM10|ug/m^3|         47|                 Id.|\n|         12|     Nitrogen oxides|    NOx|ug/m^3|          8|   Chemiluminescence|\n|         14|               Ozone|     O3|ug/m^3|          6|Ultraviolet absor...|\n|         20|             Toluene|    TOL|ug/m^3|         59|  Gas chromatography|\n|         30|             Benzene|    BEN|ug/m^3|         59|                 Id.|\n|         35|        Ethylbenzene|    EBE|ug/m^3|         59|                 Id.|\n|         37|         Methaxylene|    MXY|ug/m^3|         59|                 Id.|\n|         38|          Paraxylene|    PXY|ug/m^3|         59|                 Id.|\n|         39|         Orthoxylene|    OXY|ug/m^3|         59|                 Id.|\n|         42|Total hydrocarbon...|    TCH|mg/m^3|          2|    Flame ionization|\n|         43|             Methane|    CH4|mg/m^3|          2|                 Id.|\n|         44|Non-methane hydro...|   NMHC|mg/m^3|          2|                 Id.|\n+-----------+--------------------+-------+------+-----------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType\n",
    "\n",
    "magnitudes = [ Row(1, \"Sulphur dioxide\", \"SO2\", \"ug/m^3\", 38, \"Ultraviolet fluorescence\"),\n",
    "               Row(6, \"Carbon monoxide\", \"CO\", \"mg/m^3\", 48, \"Infrared absorption\"),\n",
    "               Row(7, \"Nitrogen monoxide\", \"NO\", \"ug/m^3\", 8, \"Chemiluminescence\"),\n",
    "               Row(8, \"Nitrogen dioxide\", \"NO2\", \"ug/m^3\", 8, \"Id.\"),\n",
    "               Row(9, \"Particles < 250um\", \"PM2.5\", \"ug/m^3\", 47, \"Microbalance\"),\n",
    "               Row(10, \"Particles < 10um\", \"PM10\", \"ug/m^3\", 47, \"Id.\"),\n",
    "               Row(12, \"Nitrogen oxides\", \"NOx\", \"ug/m^3\", 8, \"Chemiluminescence\"),\n",
    "               Row(14, \"Ozone\", \"O3\", \"ug/m^3\", 6, \"Ultraviolet absorption\"),\n",
    "               Row(20, \"Toluene\", \"TOL\", \"ug/m^3\", 59, \"Gas chromatography\"),\n",
    "               Row(30, \"Benzene\", \"BEN\", \"ug/m^3\", 59, \"Id.\"),\n",
    "               Row(35, \"Ethylbenzene\", \"EBE\", \"ug/m^3\", 59, \"Id.\"),\n",
    "               Row(37, \"Methaxylene\", \"MXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "               Row(38, \"Paraxylene\", \"PXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "               Row(39, \"Orthoxylene\", \"OXY\", \"ug/m^3\", 59, \"Id.\"),\n",
    "               Row(42, \"Total hydrocarbons (hexane)\", \"TCH\", \"mg/m^3\", 2, \"Flame ionization\"),\n",
    "               Row(43, \"Methane\", \"CH4\", \"mg/m^3\", 2, \"Id.\"),\n",
    "               Row(44, \"Non-methane hydrocarbons (hexane)\", \"NMHC\", \"mg/m^3\", 2, \"Id.\") ]\n",
    "magnitudesSchema = StructType([ StructField(\"magnitudeId\", IntegerType(), False),\n",
    "                                StructField(\"magnitudeName\", StringType(), True),\n",
    "                                StructField(\"formula\", StringType(), True),\n",
    "                                StructField(\"unit\", StringType(), True),\n",
    "                                StructField(\"techniqueId\", IntegerType(), True), \n",
    "                               StructField(\"techniqueName\", StringType(), True) ])\n",
    "magnitudesDF = spark.createDataFrame(magnitudes, magnitudesSchema)\n",
    "magnitudesDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a Dataframe called `enrichedAqDF` combining `aqDF` and `magnitudesDF`, which displays all the columns in `aqDF`but replacing column `MAGNITUDE` by column `magnitudeName`available in `magnitudesDF`, and removing all pair columns from `H01`, `V01` to `H24`, `V24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+----+-------+---------------+-----------------+----+-----+---+\n|PROVINCE|TOWN|STATION|  MAGNITUDENAME|SAMPLING_LOCATION|YEAR|MONTH|DAY|\n+--------+----+-------+---------------+-----------------+----+-----+---+\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 28|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 27|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 26|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 25|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 24|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 23|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 22|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 21|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 20|\n|      28|  79|     57|Sulphur dioxide|    28079057_1_38|2019|    2| 19|\n+--------+----+-------+---------------+-----------------+----+-----+---+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "enrichedAqDF = aqDF.join(magnitudesDF.withColumnRenamed(\"magnitudeId\",\"MAGNITUDE\"),\"MAGNITUDE\")\\\n",
    "    .select(\"PROVINCE\",\"TOWN\",\"STATION\",\"magnitudeName\",\"SAMPLING_LOCATION\",\"YEAR\",\"MONTH\",\"DAY\")\\\n",
    "    .withColumnRenamed(\"magnitudeName\", \"MAGNITUDENAME\")\n",
    "enrichedAqDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}